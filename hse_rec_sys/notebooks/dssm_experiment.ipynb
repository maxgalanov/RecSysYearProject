{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef8d903-63ca-41c5-8c6e-b455b817d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as scs\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import json\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import collections\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils.data import MatchDataGenerator, df_to_dict\n",
    "from utils.basic_layers import MLP, EmbeddingLayer\n",
    "from utils.features import SparseFeature, SequenceFeature\n",
    "from utils.match import Annoy, generate_seq_feature_match, gen_model_input\n",
    "from utils.metrics import topk_metrics\n",
    "from utils.trainer import MatchTrainer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf78efb3-6760-4c5d-af59-dd6e63f25b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_10k.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee2892bc-605a-42c9-a01c-38bbe6499b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['release', 'artist_name', 'artist_country', 'artist_city', 'year', 'title', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea837cc-d4b7-40ba-b7f2-423ae5701b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6fbf6970611d01e10aebeab374f461116155867e</td>\n",
       "      <td>SOPVPCY12A81C23555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fa8a8753518e6c2d3713990dc2a172ea17000b80</td>\n",
       "      <td>SOBSMEQ12AB018282F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9fdf63587a7a963e383ea2f1b58d1014377caab</td>\n",
       "      <td>SONQEYS12AF72AABC9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e329cc2012d31242297d294fa0279b79a1bd5cc7</td>\n",
       "      <td>SOHTAXD12A8C141E75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a9178398fa6377a340d5b9b6be87de32b4059a2</td>\n",
       "      <td>SOAWWJW12AB01814F5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id             song_id  play_count\n",
       "0  6fbf6970611d01e10aebeab374f461116155867e  SOPVPCY12A81C23555           1\n",
       "1  fa8a8753518e6c2d3713990dc2a172ea17000b80  SOBSMEQ12AB018282F           1\n",
       "2  c9fdf63587a7a963e383ea2f1b58d1014377caab  SONQEYS12AF72AABC9           1\n",
       "3  e329cc2012d31242297d294fa0279b79a1bd5cc7  SOHTAXD12A8C141E75           1\n",
       "4  2a9178398fa6377a340d5b9b6be87de32b4059a2  SOAWWJW12AB01814F5           2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5facd9f9-12c4-405e-bb0d-d91f4bb49b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"cat_id\"] = data[\"genres\"].apply(lambda x: x.split(\"|\")[0])\n",
    "user_col, item_col = \"user_id\", \"song_id\"\n",
    "sparse_features = ['user_id', 'song_id']\n",
    "# sparse_features = ['user_id', 'movie_id', 'gender', 'age', 'occupation', 'zip', \"cat_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b9263d3-594c-4edc-92e5-70457ead554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './saved/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "# print(f'Before encoding: \\n {data[sparse_features].tail()}')\n",
    "\n",
    "feature_max_idx = {}\n",
    "for feature in sparse_features:\n",
    "    encoder = LabelEncoder()\n",
    "    data[feature] = encoder.fit_transform(data[feature]) + 1 # лучше энкодить не с 0, особенно в sequential NN\n",
    "    feature_max_idx[feature] = data[feature].max() + 1\n",
    "    if feature == user_col:\n",
    "        user_map = {encode_id + 1: raw_id for encode_id, raw_id in enumerate(encoder.classes_)}\n",
    "    if feature == item_col:\n",
    "        item_map = {encode_id + 1: raw_id for encode_id, raw_id in enumerate(encoder.classes_)}\n",
    "np.save(save_dir + \"raw_id_maps.npy\", (user_map, item_map))\n",
    "\n",
    "# print(f'After encoding: \\n {data[sparse_features].tail()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc0e0b7-1302-4db3-adec-cc6a1da68c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_cols = [\"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
    "user_cols = [\"user_id\"]\n",
    "\n",
    "item_cols = ['song_id']\n",
    "user_profile = data[user_cols].drop_duplicates('user_id')\n",
    "item_profile = data[item_cols].drop_duplicates('song_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3105e5bb-06b4-4f6a-aa65-13cf70c2464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generate sequence features: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 1107.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train: 39440, n_test: 70\n",
      "0 cold start users droped \n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = generate_seq_feature_match(data,\n",
    "                                               user_col,\n",
    "                                               item_col,\n",
    "                                               item_attribute_cols=[],\n",
    "                                               sample_method=1,\n",
    "                                               mode=0,\n",
    "                                               neg_ratio=3,\n",
    "                                               min_item=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47422f88-3338-48cf-98b8-341a0fe004c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = gen_model_input(df_train, user_profile, user_col, item_profile, item_col, seq_max_len=50)\n",
    "x_test = gen_model_input(df_test, user_profile, user_col, item_profile, item_col, seq_max_len=50)\n",
    "y_train = x_train[\"label\"]\n",
    "y_test = x_test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb4a7f6-921b-42f1-858c-2eb5d87d1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = [\n",
    "    SparseFeature(feature_name, vocab_size=feature_max_idx[feature_name], embed_dim=16) for feature_name in user_cols\n",
    "]\n",
    "\n",
    "user_features += [\n",
    "    SequenceFeature(\"hist_song_id\",\n",
    "                    vocab_size=feature_max_idx[\"song_id\"],\n",
    "                    embed_dim=16,\n",
    "                    pooling=\"mean\",\n",
    "                    shared_with=\"song_id\")\n",
    "]\n",
    "\n",
    "item_features = [\n",
    "    SparseFeature(feature_name, vocab_size=feature_max_idx[feature_name], embed_dim=16) for feature_name in item_cols\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "983cc906-5c44-47ef-a178-cad369a69428",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_item = df_to_dict(item_profile)\n",
    "test_user = x_test\n",
    "data_generator = MatchDataGenerator(x=x_train, y=y_train)\n",
    "train_dl, test_dl, item_dl = data_generator.generate_dataloader(test_user, all_item, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85ae35db-fabd-4ace-a2f8-4ebb1ad850d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DSSM(torch.nn.Module):\n",
    "    \"\"\"Deep Structured Semantic Model\n",
    "    Args:\n",
    "        user_features (list[Feature Class]): training by the user tower module.\n",
    "        item_features (list[Feature Class]): training by the item tower module.\n",
    "        temperature (float): temperature factor for similarity score, default to 1.0.\n",
    "        user_params (dict): the params of the User Tower module, \n",
    "        keys include:`{\"dims\":list, \"activation\":str, \"dropout\":float, \"output_layer\":bool`}.\n",
    "        item_params (dict): the params of the Item Tower module, keys include:`{\"dims\":list, \"activation\":str, \"dropout\":float, \"output_layer\":bool`}.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, user_features, item_features, user_params, item_params, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.user_features = user_features\n",
    "        self.item_features = item_features\n",
    "        self.temperature = temperature\n",
    "        self.user_dims = sum([f.embed_dim for f in user_features])\n",
    "        self.item_dims = sum([f.embed_dim for f in item_features])\n",
    "\n",
    "        self.embedding = EmbeddingLayer(user_features + item_features)\n",
    "        self.user_mlp = MLP(self.user_dims, output_layer=False, **user_params)\n",
    "        self.item_mlp = MLP(self.item_dims, output_layer=False, **item_params)\n",
    "        self.mode = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        item_embedding = self.item_tower(x)\n",
    "        user_embedding = self.user_tower(x)\n",
    "        # item_embedding = self.item_tower(x)\n",
    "        if self.mode == \"user\":\n",
    "            return user_embedding\n",
    "        if self.mode == \"item\":\n",
    "            return item_embedding\n",
    "        # y = torch.mul(user_embedding, item_embedding).sum(dim=2)\n",
    "        # y = y / self.temperature\n",
    "        y = F.cosine_similarity(item_embedding, user_embedding, dim=1)\n",
    "        return y\n",
    "\n",
    "    def item_tower(self, x):\n",
    "        if self.mode == \"user\":\n",
    "            return None\n",
    "        # Какая тут размерность? \n",
    "        # print(x['song_id'].shape)\n",
    "        # print(self.item_features)\n",
    "        input_item = self.embedding(x, self.item_features, squeeze_dim=True)\n",
    "        item_embedding = self.item_mlp(input_item)\n",
    "        item_embedding = F.normalize(item_embedding, p=2, dim=1)\n",
    "        return item_embedding\n",
    "    \n",
    "    def user_tower(self, x):\n",
    "        if self.mode == \"item\":\n",
    "            return None\n",
    "        # print(x['user_id'].shape)\n",
    "        input_user = self.embedding(x, self.user_features, squeeze_dim=True)\n",
    "        user_embedding = self.user_mlp(input_user)\n",
    "        user_embedding = F.normalize(user_embedding, p=2, dim=1)\n",
    "        return user_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79eadb60-1d80-43e9-9f91-ba22b59d0ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|                                                                                                                                                                       | 0/309 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 23\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m DSSM(user_features,\n\u001b[1;32m      2\u001b[0m              item_features,\n\u001b[1;32m      3\u001b[0m              temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m              })\n\u001b[1;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MatchTrainer(model,\n\u001b[1;32m     14\u001b[0m                        mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     15\u001b[0m                        optimizer_params\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m                        n_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     20\u001b[0m                        device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/Test_nick/Recs/utils/trainer.py:99\u001b[0m, in \u001b[0;36mMatchTrainer.fit\u001b[0;34m(self, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch:\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_i)\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m epoch_i \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Code/Test_nick/Recs/utils/trainer.py:87\u001b[0m, in \u001b[0;36mMatchTrainer.train_one_epoch\u001b[0;34m(self, data_loader, log_interval)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x_dict)\n\u001b[0;32m---> 87\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     89\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/mnt/700G_SSD/anaconda3/envs/NickEnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/700G_SSD/anaconda3/envs/NickEnv/lib/python3.10/site-packages/torch/nn/modules/loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/700G_SSD/anaconda3/envs/NickEnv/lib/python3.10/site-packages/torch/nn/functional.py:3098\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3095\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3096\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "model = DSSM(user_features,\n",
    "             item_features,\n",
    "             temperature=0.02,\n",
    "             user_params={\n",
    "                 \"dims\": [256, 128, 64],\n",
    "                 \"activation\": 'prelu',\n",
    "             },\n",
    "             item_params={\n",
    "                 \"dims\": [256, 128, 64],\n",
    "                 \"activation\": 'prelu',\n",
    "             })\n",
    "\n",
    "trainer = MatchTrainer(model,\n",
    "                       mode=0,\n",
    "                       optimizer_params={\n",
    "                           \"lr\": 1e-2,\n",
    "                           \"weight_decay\": 1e-5\n",
    "                       },\n",
    "                       n_epoch=3,\n",
    "                       device='cpu')\n",
    "\n",
    "\n",
    "trainer.fit(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da3f74-569b-447f-ab46-b9dd8ebedfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NickEnv",
   "language": "python",
   "name": "nickenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
