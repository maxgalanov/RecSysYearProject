{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf21782-1192-4b01-b7d2-80ea432ac113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as scs\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import json\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import collections\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils.data import MatchDataGenerator, df_to_dict\n",
    "from utils.basic_layers import MLP, EmbeddingLayer\n",
    "from utils.features import SparseFeature, SequenceFeature\n",
    "from utils.match import Annoy, generate_seq_feature_match, gen_model_input\n",
    "from utils.metrics import topk_metrics\n",
    "from utils.trainer import MatchTrainer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6d93bd-ffe5-4899-a256-61c41484d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_10k.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "429c0e1c-8f1a-4485-8124-d5cc8b671857",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['release', 'artist_name', 'artist_country', 'artist_city', 'year', 'title', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8adbbeaa-6964-4a3e-ad1d-87d0d039fa51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>song_id</th>\n",
       "      <th>play_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6fbf6970611d01e10aebeab374f461116155867e</td>\n",
       "      <td>SOPVPCY12A81C23555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fa8a8753518e6c2d3713990dc2a172ea17000b80</td>\n",
       "      <td>SOBSMEQ12AB018282F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9fdf63587a7a963e383ea2f1b58d1014377caab</td>\n",
       "      <td>SONQEYS12AF72AABC9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e329cc2012d31242297d294fa0279b79a1bd5cc7</td>\n",
       "      <td>SOHTAXD12A8C141E75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a9178398fa6377a340d5b9b6be87de32b4059a2</td>\n",
       "      <td>SOAWWJW12AB01814F5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id             song_id  play_count\n",
       "0  6fbf6970611d01e10aebeab374f461116155867e  SOPVPCY12A81C23555           1\n",
       "1  fa8a8753518e6c2d3713990dc2a172ea17000b80  SOBSMEQ12AB018282F           1\n",
       "2  c9fdf63587a7a963e383ea2f1b58d1014377caab  SONQEYS12AF72AABC9           1\n",
       "3  e329cc2012d31242297d294fa0279b79a1bd5cc7  SOHTAXD12A8C141E75           1\n",
       "4  2a9178398fa6377a340d5b9b6be87de32b4059a2  SOAWWJW12AB01814F5           2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c8ca0f-278d-4f57-b5b0-59201a561608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"cat_id\"] = data[\"genres\"].apply(lambda x: x.split(\"|\")[0])\n",
    "user_col, item_col = \"user_id\", \"song_id\"\n",
    "sparse_features = ['user_id', 'song_id']\n",
    "# sparse_features = ['user_id', 'movie_id', 'gender', 'age', 'occupation', 'zip', \"cat_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b5a8e2e-8e21-4bfa-89ef-c7628ac7a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './saved/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "    \n",
    "# print(f'Before encoding: \\n {data[sparse_features].tail()}')\n",
    "\n",
    "feature_max_idx = {}\n",
    "for feature in sparse_features:\n",
    "    encoder = LabelEncoder()\n",
    "    data[feature] = encoder.fit_transform(data[feature]) + 1 # лучше энкодить не с 0, особенно в sequential NN\n",
    "    feature_max_idx[feature] = data[feature].max() + 1\n",
    "    if feature == user_col:\n",
    "        user_map = {encode_id + 1: raw_id for encode_id, raw_id in enumerate(encoder.classes_)}\n",
    "    if feature == item_col:\n",
    "        item_map = {encode_id + 1: raw_id for encode_id, raw_id in enumerate(encoder.classes_)}\n",
    "np.save(save_dir + \"raw_id_maps.npy\", (user_map, item_map))\n",
    "\n",
    "# print(f'After encoding: \\n {data[sparse_features].tail()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23013c15-776c-4392-a657-989ca31fe0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_cols = [\"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
    "user_cols = [\"user_id\"]\n",
    "\n",
    "item_cols = ['song_id']\n",
    "user_profile = data[user_cols].drop_duplicates('user_id')\n",
    "item_profile = data[item_cols].drop_duplicates('movie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b38485e1-658f-48b8-a529-3b8693c01072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generate sequence features: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 260.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train: 39440, n_test: 70\n",
      "0 cold start users droped \n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = generate_seq_feature_match(data,\n",
    "                                               user_col,\n",
    "                                               item_col,\n",
    "                                               item_attribute_cols=[],\n",
    "                                               sample_method=1,\n",
    "                                               mode=0,\n",
    "                                               neg_ratio=3,\n",
    "                                               min_item=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df7b7d13-3aaa-42ed-be87-f0f7f58364b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = gen_model_input(df_train, user_profile, user_col, item_profile, item_col, seq_max_len=50)\n",
    "x_test = gen_model_input(df_test, user_profile, user_col, item_profile, item_col, seq_max_len=50)\n",
    "\n",
    "y_train = x_train[\"label\"]\n",
    "y_test = x_test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "842b0250-8ba0-4d02-9b9a-6bec26f7296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = [\n",
    "    SparseFeature(feature_name, vocab_size=feature_max_idx[feature_name], embed_dim=16) for feature_name in user_cols\n",
    "]\n",
    "\n",
    "user_features += [\n",
    "    SequenceFeature(\"hist_song_id\",\n",
    "                    vocab_size=feature_max_idx[\"song_id\"],\n",
    "                    embed_dim=16,\n",
    "                    pooling=\"mean\",\n",
    "                    shared_with=\"song_id\")\n",
    "]\n",
    "\n",
    "item_features = [\n",
    "    \n",
    "    SparseFeature(feature_name, vocab_size=feature_max_idx[feature_name], embed_dim=16) for feature_name in item_cols\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b81377dd-f074-4000-bb0c-d2d23045f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_item = df_to_dict(item_profile)\n",
    "\n",
    "test_user = x_test\n",
    "data_generator = MatchDataGenerator(x=x_train, y=y_train)\n",
    "train_dl, test_dl, item_dl = data_generator.generate_dataloader(test_user, all_item, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c039f43-4769-4bef-8cf0-349ecbb99f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoutubeDNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The match model mentioned in `Deep Neural Networks for YouTube Recommendations` paper.\n",
    "    It's a DSSM match model trained by global softmax loss on list-wise samples. \n",
    "    In origin paper, item dnn tower is missing.\n",
    "    Args:\n",
    "        user_features (list[Feature Class]): training by the user tower module.\n",
    "        item_features (list[Feature Class]): training by the embedding table, it's the item id feature.\n",
    "        neg_item_feature (list[Feature Class]): training by the embedding table, it's the negative items id feature.\n",
    "        user_params (dict): the params of the User Tower module, \n",
    "        keys include:`{\"dims\":list, \"activation\":str, \"dropout\":float, \"output_layer\":bool`}.\n",
    "        temperature (float): temperature factor for similarity score, default to 1.0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, user_features, item_features, neg_item_feature, user_params, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.user_features = user_features\n",
    "        self.item_features = item_features\n",
    "        self.neg_item_feature = neg_item_feature\n",
    "        self.temperature = temperature\n",
    "        self.user_dims = sum([fea.embed_dim for fea in user_features])\n",
    "        self.embedding = EmbeddingLayer(user_features + item_features)\n",
    "        self.user_mlp = MLP(self.user_dims, output_layer=False, **user_params)\n",
    "        self.mode = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        user_embedding = self.user_tower(x)\n",
    "        item_embedding = self.item_tower(x)\n",
    "        if self.mode == \"user\":\n",
    "            return user_embedding\n",
    "        if self.mode == \"item\":\n",
    "            return item_embedding\n",
    "\n",
    "        y = torch.mul(user_embedding, item_embedding).sum(dim=2)\n",
    "        y = y / self.temperature\n",
    "        return y\n",
    "\n",
    "    def user_tower(self, x):\n",
    "        if self.mode == \"item\":\n",
    "            return None\n",
    "        # [batch_size, num_features * deep_dims]\n",
    "        input_user = self.embedding(x, self.user_features, squeeze_dim=True)\n",
    "        # [batch_size, 1, embed_dim]\n",
    "        user_embedding = self.user_mlp(input_user).unsqueeze(1)\n",
    "        user_embedding = F.normalize(user_embedding, p=2, dim=2)\n",
    "        if self.mode == \"user\":\n",
    "            return user_embedding.squeeze(1)\n",
    "        return user_embedding\n",
    "\n",
    "    def item_tower(self, x):\n",
    "        if self.mode == \"user\":\n",
    "            \n",
    "            return None\n",
    "        #[batch_size, 1, embed_dim]\n",
    "        pos_embedding = self.embedding(x, self.item_features, squeeze_dim=False)\n",
    "        pos_embedding = F.normalize(pos_embedding, p=2, dim=2)\n",
    "        # inference embedding mode\n",
    "        if self.mode == \"item\":\n",
    "            # [batch_size, embed_dim]\n",
    "            return pos_embedding.squeeze(1)\n",
    "        #[batch_size, n_neg_items, embed_dim]\n",
    "        neg_embeddings = self.embedding(x, self.neg_item_feature,\n",
    "                                        squeeze_dim=False).squeeze(1)\n",
    "        neg_embeddings = F.normalize(neg_embeddings, p=2, dim=2)\n",
    "        # [batch_size, 1 + n_neg_items, embed_dim]\n",
    "        return torch.cat((pos_embedding, neg_embeddings), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d56a24bf-eb53-4329-9f5f-93457b9e7098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generate sequence features: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 1489.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train: 9860, n_test: 70\n",
      "0 cold start users droped \n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = generate_seq_feature_match(data,\n",
    "                                               user_col,\n",
    "                                               item_col,\n",
    "                                               item_attribute_cols=[],\n",
    "                                               sample_method=1,\n",
    "                                               mode=2,\n",
    "                                               neg_ratio=3,\n",
    "                                               min_item=0)\n",
    "x_train = gen_model_input(df_train, user_profile, user_col, item_profile, item_col, seq_max_len=50)\n",
    "y_train = np.array([0] * df_train.shape[0])\n",
    "x_test = gen_model_input(df_test, user_profile, user_col, item_profile, item_col, seq_max_len=50)\n",
    "\n",
    "# user_cols = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
    "user_cols = ['user_id']\n",
    "\n",
    "user_features = [SparseFeature(name, vocab_size=feature_max_idx[name], embed_dim=16) for name in user_cols]\n",
    "user_features += [\n",
    "    SequenceFeature(\"hist_song_id\",\n",
    "                    vocab_size=feature_max_idx[\"song_id\"],\n",
    "                    embed_dim=16,\n",
    "                    pooling=\"mean\",\n",
    "                    shared_with=\"song_id\")\n",
    "]\n",
    "\n",
    "item_features = [SparseFeature('song_id', vocab_size=feature_max_idx['song_id'], embed_dim=16)]\n",
    "neg_item_feature = [\n",
    "    SequenceFeature('neg_items',\n",
    "                    vocab_size=feature_max_idx['song_id'],\n",
    "                    embed_dim=16,\n",
    "                    pooling=\"concat\",\n",
    "                    shared_with=\"song_id\")\n",
    "]\n",
    "\n",
    "all_item = df_to_dict(item_profile)\n",
    "test_user = x_test\n",
    "\n",
    "dg = MatchDataGenerator(x=x_train, y=y_train)\n",
    "train_dl, test_dl, item_dl = dg.generate_dataloader(test_user, all_item, batch_size=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fc17e70-cf20-4982-b541-6cf877524aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_evaluation(user_embedding, item_embedding, test_user, all_item, user_col='user_id', item_col='song_id',\n",
    "                     raw_id_maps=\"./raw_id_maps.npy\", topk=10):\n",
    "    \n",
    "    # Fit Annoy tree on item embeddings\n",
    "    annoy = Annoy(n_trees=10)\n",
    "    annoy.fit(item_embedding)\n",
    "\n",
    "    # For each user get top-k similar items\n",
    "    user_map, item_map = np.load(raw_id_maps, allow_pickle=True)\n",
    "    match_res = collections.defaultdict(dict)\n",
    "    for user_id, user_emb in zip(test_user[user_col], user_embedding):\n",
    "        items_idx, items_scores = annoy.query(v=user_emb, n=topk)\n",
    "        match_res[user_map[user_id]] = np.vectorize(item_map.get)(all_item[item_col][items_idx])\n",
    "\n",
    "    # Get ground truth\n",
    "    data = pd.DataFrame({user_col: test_user[user_col], item_col: test_user[item_col]})\n",
    "    data[user_col] = data[user_col].map(user_map)\n",
    "    data[item_col] = data[item_col].map(item_map)\n",
    "    user_pos_item = data.groupby(user_col).agg(list).reset_index()\n",
    "    ground_truth = dict(zip(user_pos_item[user_col], user_pos_item[item_col]))\n",
    "\n",
    "    # Compute top-k metrics\n",
    "    \n",
    "    y_true = ground_truth\n",
    "    y_pred = match_res\n",
    "\n",
    "    l = list(range(1, topk+1))\n",
    "    out = topk_metrics(y_true=ground_truth, y_pred=match_res, topKs=l)\n",
    "    return y_pred, y_true, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1473c68-b896-4096-bff3-56c20f017262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 30.73it/s, loss=13.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.54it/s, loss=10.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 32.70it/s, loss=9.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.94it/s, loss=7.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.42it/s, loss=6.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.62it/s, loss=6.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.89it/s, loss=5.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.84it/s, loss=4.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 32.71it/s, loss=4.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 34.22it/s, loss=3.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.90it/s, loss=3.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 32.82it/s, loss=3.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.75it/s, loss=2.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 37.15it/s, loss=2.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.23it/s, loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.49it/s, loss=2.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.19it/s, loss=2.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.59it/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 35.87it/s, loss=1.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.44it/s, loss=1.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 37.17it/s, loss=1.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.79it/s, loss=1.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 36.85it/s, loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 37.05it/s, loss=1.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "user inference: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.76it/s]\n",
      "item inference: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.77it/s]\n"
     ]
    }
   ],
   "source": [
    "model = YoutubeDNN(user_features, item_features, neg_item_feature, \n",
    "                   user_params={\"dims\": [128, 64, 16]}, temperature=0.02)\n",
    "\n",
    "trainer = MatchTrainer(model,\n",
    "                       mode=2,\n",
    "                       \n",
    "                       optimizer_params={\n",
    "                           \"lr\": 1e-2,\n",
    "                           \"weight_decay\": 1e-5\n",
    "                       },\n",
    "                       n_epoch=24,\n",
    "                       device='cpu',\n",
    "                       model_path=save_dir)\n",
    "\n",
    "trainer.fit(train_dl)\n",
    "\n",
    "print(\"inference embedding\")\n",
    "user_embedding = trainer.inference_embedding(model=model, mode=\"user\", data_loader=test_dl, model_path=save_dir)\n",
    "item_embedding = trainer.inference_embedding(model=model, mode=\"item\", data_loader=item_dl, model_path=save_dir)\n",
    "# match_evaluation(user_embedding, item_embedding, test_user, all_item, topk=100, raw_id_maps=\"./saved/raw_id_maps.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7221e958-1321-46fe-9958-3e26ab09fa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3573, -0.1890,  0.2433,  ...,  0.2958, -0.2846, -0.3350],\n",
       "        [ 0.1236, -0.1122, -0.0582,  ...,  0.1327, -0.0906, -0.1197],\n",
       "        [ 0.1914,  0.1711, -0.6693,  ...,  0.1815,  0.1360, -0.0446],\n",
       "        ...,\n",
       "        [-0.2599, -0.1943, -0.2429,  ..., -0.2332, -0.2364, -0.2364],\n",
       "        [-0.2309,  0.2465,  0.3711,  ...,  0.2151,  0.2085, -0.2146],\n",
       "        [-0.1706, -0.2636,  0.1105,  ...,  0.1664, -0.2664, -0.2228]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ddc660b-a09c-4b4a-8ce6-40683f262b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_true, ou = match_evaluation(user_embedding, item_embedding, test_user, all_item, topk=30, raw_id_maps=\"./saved/raw_id_maps.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c76d424f-65da-4f47-8b7b-a5b974e43c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_youtube = ou['Precision']\n",
    "rec_youtube = ou['Recall']\n",
    "map_youtube = ou['MAP']\n",
    "mar_youtube = ou['MAR']\n",
    "ndcg_k_youtube = ou['ndcg_k']\n",
    "coverage = ou['coverage']\n",
    "personalization = ou['personalization']\n",
    "novelty = ou['novelty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a5b51-567e-4de5-abf4-4452af592f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_numpy_data = 'metrics/youtube_prec'\n",
    "np.save(path_numpy_data, prec_youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17dbb59-22b6-49e7-8793-a1beb152cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_numpy_data = 'metrics/youtube_rec'\n",
    "np.save(path_numpy_data, rec_youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241b35f-bcc7-425e-b483-be53eeb42c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_numpy_data = 'metrics/youtube_map'\n",
    "np.save(path_numpy_data, map_youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d78bf-0833-440b-b913-d7432b4b82fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_numpy_data = 'metrics/youtube_mar'\n",
    "np.save(path_numpy_data, mar_youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09774145-5f96-49a5-bbed-4396f8e2e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_numpy_data = 'metrics/youtube_ndcg'\n",
    "np.save(path_numpy_data, ndcg_k_youtube)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NickEnv",
   "language": "python",
   "name": "nickenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
